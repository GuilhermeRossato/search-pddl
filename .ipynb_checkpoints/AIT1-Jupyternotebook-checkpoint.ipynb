{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d15b72335f7299db19eb2b7a48018058",
     "grade": false,
     "grade_id": "cell-3923f17ae0a87128",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Assignment 1: Planning using Heuristic Search\n",
    "\n",
    "**Felipe Meneguzzi**  \n",
    "**Mauricio Magnaguagno (PhD Student)**  \n",
    "**Leonardo Rosa Amado (PhD Student)**\n",
    "\n",
    "Computer Science (4646A-4):\n",
    "- Assigned: 30 August\n",
    "- Due: 25 September\n",
    "\n",
    "Computer Engineering (4621A-4):\n",
    "- Assigned: 28 August\n",
    "- Due: 23 September\n",
    "\n",
    "## Assignment Overview\n",
    "\n",
    "<img align=\"right\" src=\"planning-assignment.png\"/>\n",
    "\n",
    "The goal of this work is to implement the core functions of an automated planner. You will implement three main functions in this assignment:\n",
    "- Implement the **Max-Cost** heuristic function.\n",
    "- Implement a function capable of validating a plan given a domain and a problem.\n",
    "- Finally, implement the heuristic search **A\\***\n",
    "\n",
    "After implementing the required functions, you must write a 2-page paper. The entire package must be delivered using GitHub, where your implemented functions must be contained in this Jupyter Notebook, and the paper as a separate **pdf** file committed in the same Github repository (the template is in the ```paper``` folder).\n",
    "\n",
    "## Experimentation\n",
    "\n",
    "- You can test your implementation with the provided domains and problems:\n",
    "  - [blocksworld](examples/blocksworld)\n",
    "  - [dinner](examples/dinner)\n",
    "  - [dwr](examples/dwr)\n",
    "  - [tsp](examples/tsp)\n",
    "\n",
    "- Planning tools and extra domains and problems to sanity check your own implementation:\n",
    "  - [Web-Planner](https://web-planner.herokuapp.com/)\n",
    "  - [editor.planning.domains](http://editor.planning.domains/)\n",
    "  - IPC domains and problems can be found in [potassco/pddl-instances](https://github.com/potassco/pddl-instances)\n",
    "\n",
    "\n",
    "## Grading\n",
    "\n",
    "In order to properly evaluate your work and thought process, you will write a **2-page** report in the AAAI two-column format explaining your encoding and experiments. \n",
    "These guidelines are to be followed **exactly**. \n",
    "**Reports that are less than two pages of actual content, or not in format will receive 0 marks for the report criterion.** \n",
    "This report will be included in the deliverables of the assignment. \n",
    "[The formatting instructions are available at ShareLatex (AAAI Press)](https://www.sharelatex.com/templates/journals/aaai-press). \n",
    "The report must have the following sections:\n",
    "\n",
    "- An introduction with your understanding of the problem domain, outlining the remainder of the paper;\n",
    "- Three sections explaining each part of your implementation (search, heuristic, and validator).\n",
    "- One experimentation section where you measure the performance of the planner using your action formalisation for each of the domains, on multiple problems.\n",
    "- One conclusion section, where you will summarise your experience in encoding planning domains and discuss the performance of the planner, and any limitations encountered in solving the problems you encoded.\n",
    "\n",
    "Grading will consider elements of your encoding, experimentation and reporting of the work done. \n",
    "The criteria, as well as their weight in the final grade is as follows:\n",
    "\n",
    "- Implementation (70%):\n",
    "  - Heuristic function (20%);\n",
    "  - Validator (20%);\n",
    "  - Heuristic search (30%):\n",
    "      - Correctness and optimality (20%); and\n",
    "      - Runtime efficiency (10%).\n",
    "- Overall report readability (20%) â€” how accessible and coherent your explanation of your implementation is;\n",
    "- Code readability (10%).\n",
    "\n",
    "## Collaboration Policy\n",
    "\n",
    "You must work on this project **individually**. \n",
    "You are free to discuss high-level design issues with the people in your class, but every aspect of your actual formalisation must be entirely your own work.\n",
    "Furthermore, there can be no textual similarities in the reports generated by each group. \n",
    "Plagiarism, no matter the degree, will result in forfeiture of the entire grade of this assignment.\n",
    "\n",
    "## Sections\n",
    "\n",
    "- [Heuristic](#Heuristic)\n",
    "  - [Implement the heuristic function](#Implement-the-heuristic-function)\n",
    "  - [Test heuristic function](#Test-heuristic-function)\n",
    "- [Validator](#Validator)\n",
    "  - [Implement the validate function](#Implement-the-validate-function)\n",
    "  - [Test validate function](#Test-validate-function)\n",
    "- [Planner](#Planner)\n",
    "  - [Implement the planner solve function](#Implement-the-planner-solve-function)\n",
    "  - [Test planner completeness and optimality](#Test-planner-completeness-and-optimality)\n",
    "  - [Test planner output time](#Test-planner-output-time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "move\n",
      "['r1', 'l1', 'l2']\n",
      "frozenset({('adjacent', 'l1', 'l2'), ('at', 'r1', 'l1')})\n",
      "frozenset({('occupied', 'l2')})\n",
      "frozenset({('at', 'r1', 'l2'), ('occupied', 'l2')})\n",
      "frozenset({('at', 'r1', 'l1'), ('occupied', 'l1')})\n"
     ]
    }
   ],
   "source": [
    "from pddl.action import Action\n",
    "from pddl.state import applicable, apply\n",
    "\n",
    "# Objects example\n",
    "\n",
    "# An action to move robot r1 from location l1 to location l2\n",
    "a1 = Action(\n",
    "    'move',\n",
    "    ['r1', 'l1', 'l2'], # parameter\n",
    "    frozenset({('at', 'r1', 'l1'), ('adjacent', 'l1', 'l2')}), # positive\n",
    "    frozenset({('occupied', 'l2')}), #negative\n",
    "    frozenset({('at', 'r1', 'l1'), ('occupied', 'l1')}), # effects added\n",
    "    frozenset({('at', 'r1', 'l2'), ('occupied', 'l2')}) # effects removed\n",
    ")\n",
    "\n",
    "# Get each element from the action\n",
    "print(a1.name)\n",
    "print(a1.parameters)\n",
    "print(a1.positive_preconditions)\n",
    "print(a1.negative_preconditions)\n",
    "print(a1.add_effects)\n",
    "print(a1.del_effects)\n",
    "\n",
    "# The list of actions contains all possible actions\n",
    "actions = [\n",
    "    a1,\n",
    "    # ...\n",
    "]\n",
    "\n",
    "# Only positive literals are present in the initial state\n",
    "initial_state = frozenset({\n",
    "    ('on', 'ca', 'pallet'),\n",
    "    ('at', 'r1', 'l1'),\n",
    "    ('belong', 'k1', 'l1'),\n",
    "    ('adjacent', 'l1', 'l2'), ('adjacent', 'l2', 'l1'), ('attached', 'q2', 'l2'),\n",
    "    ('empty', 'k2'),\n",
    "    ('attached', 'p1', 'l1'), ('occupied', 'l1'),\n",
    "    ('empty', 'k1'),\n",
    "    # ...\n",
    "})\n",
    "\n",
    "# Goal literals are split in two, positive and negative\n",
    "positive_goal = frozenset({('in', 'cb', 'p1'), ('in', 'ca', 'p1')})\n",
    "negative_goal = frozenset()\n",
    "\n",
    "# The output plan from the planner is either a list of actions or failure (None)\n",
    "# An empty plan is valid\n",
    "plan = []\n",
    "# Preconditions and effects are None when obtained from a plan file, may be filled when obtained from the planner\n",
    "plan = [\n",
    "    Action('take', ['k1', 'cc', 'cb', 'p1', 'l1'], None, None, None, None),\n",
    "    Action('load', ['k1', 'r1', 'cc', 'l1'], None, None, None, None),\n",
    "    Action('move', ['r1', 'l1', 'l2'], None, None, None, None),\n",
    "    Action('unload', ['k2', 'r1', 'cc', 'l2'], None, None, None, None)\n",
    "    # ...\n",
    "]\n",
    "# Failure\n",
    "plan = None\n",
    "\n",
    "# A valid plan is either true or false\n",
    "valid_plan   = True\n",
    "invalid_plan = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "a439a92cb0dded8a2145b1224dbb6c1d",
     "grade": false,
     "grade_id": "cell-5603c4df1ccebf1e",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from pddl.heuristic import Heuristic\n",
    "import pddl.state\n",
    "\n",
    "class MaxHeuristic(Heuristic):\n",
    "    def are_goals_satisfied(self, initial_state, positive_goals, negative_goals):\n",
    "        return (pddl.state.applicable(initial_state, positive_goals, negative_goals))\n",
    "\n",
    "    def can_apply_action_to_state(self, state, action):\n",
    "        return pddl.state.applicable(state, action.positive_preconditions, action.negative_preconditions)\n",
    "\n",
    "    def get_state_with_applied_action(self, state, action):\n",
    "        return pddl.state.apply(state, action.add_effects, action.del_effects)\n",
    "    \n",
    "    def iterate_h(self, actions, state, positive_goals, negative_goals, depth = 0):\n",
    "        if (self.are_goals_satisfied(state, positive_goals, negative_goals)):\n",
    "            return 0\n",
    "        \n",
    "        if (depth > 100): # TODO: Verificar se isso desconta nota\n",
    "            return float(\"inf\")\n",
    "        \n",
    "        best_action = None\n",
    "        best_value = None\n",
    "        # Verify each action and create a new state with it\n",
    "        for action in actions:\n",
    "            new_state = self.get_state_with_applied_action(state, action)\n",
    "            this_h = self.iterate_h(actions, new_state, positive_goals, negative_goals, depth+1)\n",
    "            if (best_action == None or best_value < this_h):\n",
    "                best_action = action\n",
    "                best_value = this_h\n",
    "        \n",
    "        return float(\"inf\") if (best_action == None) else best_value;\n",
    "\n",
    "    def h(self, actions, initial_state, positive_goals, negative_goals):\n",
    "        return self.iterate_h(actions, initial_state, positive_goals, negative_goals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "024e6082501df0b7f20b41af1e889c55",
     "grade": false,
     "grade_id": "cell-8821f1202522b75e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Heuristic\n",
    "\n",
    "## Implement the heuristic function\n",
    "\n",
    "You will implement the Max-cost heuristic. \n",
    "Return estimated distance between current ``state`` $s$ and ``goal`` $G$, a number between 0 (when $s \\models G$) and infinity (when $G$ is unreachable).\n",
    "\n",
    "$$\n",
    "h^{max}(s,g)=\\max_{g_i \\in G}\n",
    "\\begin{cases}\n",
    "0, & \\text{if } g_i \\in s\\\\\n",
    "\\min \\{cost(a) + h^{max}(s,pre(a))\\text{ | }a \\in A \\text{ and }g_i \\in \\text{eff}(a)\\} & \\text{otherwise}\\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where cost is $cost$ of the action (usually $1$), and $pre(a)$ is the set of precoditions of action $a$, and $f$ is the set of effects of actions $a$. Your code must be contained in the ``h(self, actions, initial_state, positive_goals, negative_goals)`` function in the cell below. You can create additional functions (do not forget to comment the code intelligibly). H takes the following inputs:\n",
    "- ``actions``: list of ground actions\n",
    "- ``initial_state``: initial state of the problem file\n",
    "- ``positive_goals``: positive predicates of the goal\n",
    "- ``negative_goals``: negative predicates of the goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d082b860e6c60dfd46d029e8f62401f6",
     "grade": false,
     "grade_id": "cell-1f422426e53cbdc9",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Test the heuristic function\n",
    "\n",
    "We will test the Max Heuristic using 3 different domains, dinner, tsp and dwr. The state used is the initial state of each problem. \n",
    "\n",
    "At each execution we show the expected value for the Max-cost heuristic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ade00bedf0f3855b2b42ee6bebf80f6b",
     "grade": true,
     "grade_id": "cell-cc7f08e3c117042b",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Action instance has no attribute 'positive'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5291a29bd252>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Apply Hmax to initial states of many problems from many domains\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMaxHeuristic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtest_heuristic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb1_dwr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mtest_heuristic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdwr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb2_dwr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mtest_heuristic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpb1_tsp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5291a29bd252>\u001b[0m in \u001b[0;36mtest_heuristic\u001b[0;34m(domain, problem, h, expected)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_heuristic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_domain_problem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative_goals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expected \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\", got:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'. Correct!'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mexpected\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'. False!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7ef672739244>\u001b[0m in \u001b[0;36mh\u001b[0;34m(self, actions, initial_state, positive_goals, negative_goals)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_goals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_goals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-7ef672739244>\u001b[0m in \u001b[0;36miterate_h\u001b[0;34m(self, actions, state, positive_goals, negative_goals, depth)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Verify each action and create a new state with it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0mnew_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_state_with_applied_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0mthis_h\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterate_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbest_action\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbest_value\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mthis_h\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-7ef672739244>\u001b[0m in \u001b[0;36mget_state_with_applied_action\u001b[0;34m(self, state, action)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_state_with_applied_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpddl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterate_h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_goals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Action instance has no attribute 'positive'"
     ]
    }
   ],
   "source": [
    "from pddl.pddl_parser import PDDL_Parser\n",
    "from pddl.action import Action\n",
    "from pddl.state import applicable, apply\n",
    "\n",
    "# The following should be visible to the students\n",
    "# Load some domain and some problem\n",
    "dwr = \"examples/dwr/dwr.pddl\"\n",
    "pb1_dwr = \"examples/dwr/pb1.pddl\"\n",
    "pb2_dwr = \"examples/dwr/pb2.pddl\"\n",
    "\n",
    "tsp = \"examples/tsp/tsp.pddl\"\n",
    "pb1_tsp = \"examples/tsp/pb1.pddl\"\n",
    "\n",
    "dinner = \"examples/dinner/dinner.pddl\"\n",
    "pb1_dinner = \"examples/dinner/pb1.pddl\"\n",
    "\n",
    "def parse_domain_problem(domain, problem):\n",
    "    parser = PDDL_Parser()\n",
    "    parser.parse_domain(domain)\n",
    "    parser.parse_problem(problem)\n",
    "    # Grounding process\n",
    "    actions = []\n",
    "    for action in parser.actions:\n",
    "        for act in action.groundify(parser.objects):\n",
    "            actions.append(act)\n",
    "    return parser, actions\n",
    "\n",
    "def test_heuristic(domain, problem, h, expected):\n",
    "    parser, actions = parse_domain_problem(domain, problem)\n",
    "    v = h.h(actions, parser.state, parser.positive_goals, parser.negative_goals)\n",
    "    print(\"Expected \" + str(expected) + \", got:\", str(v) + ('. Correct!' if v == expected else '. False!'))\n",
    "\n",
    "# Apply Hmax to initial states of many problems from many domains\n",
    "h = MaxHeuristic()\n",
    "test_heuristic(dwr, pb1_dwr, h, 6)\n",
    "test_heuristic(dwr, pb2_dwr, h, 0)\n",
    "test_heuristic(tsp, pb1_tsp, h, 2)\n",
    "test_heuristic(dinner, pb1_dinner, h, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9bb3a67c44f4b153c8d24f03356a56ff",
     "grade": true,
     "grade_id": "cell-dc9e9545e6fa8746",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d7172eb9679d3463cf771fdc7619da32",
     "grade": false,
     "grade_id": "cell-b65d3e7b06ea9df1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Validator\n",
    "\n",
    "## Implement the validate function\n",
    "You will now implement a validator capable of verifying if a plan is valid to a specific domain and problem. The validator must return **True** if and only if the given plan is applicable and reaches the specified goal, and **False** if the plan itself is **not** applicable **or**  the given plan does **not** achieve the specified goal. Your code must be contained in the ```validate(self, actions, initial_state, positive_goals, negative_goals, plan)``` function in the cell below. You can create additional functions (do not forget to comment the code intelligibly). Validate takes the following inputs:\n",
    "- ``actions``: list of ground actions\n",
    "- ``initial_state``: initial state of the problem file\n",
    "- ``positive_goals``: positive predicates of the goal\n",
    "- ``negative_goals``: negative predicates of the goal\n",
    "- ``plan``: plan parsed from a plan trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0d8e4e78b8d5057b36c7bb1fcd4f84c9",
     "grade": false,
     "grade_id": "cell-76b19c0ef756aadd",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from pddl.pddl_parser import PDDL_Parser\n",
    "from pddl.action import Action\n",
    "from pddl.state import applicable, apply\n",
    "\n",
    "class Validator:\n",
    "\n",
    "    def parse_plan(self, filename):\n",
    "        with open(filename,'r') as f:\n",
    "            plan = []\n",
    "            for act in f.read().splitlines():\n",
    "                act = act[1:-1].split()\n",
    "                plan.append(Action(act[0], tuple(act[1:]), None, None, None, None))\n",
    "            return plan\n",
    "\n",
    "    def validate_file(self, domainfile, problemfile, planfile):\n",
    "        return self.validate_plan(domainfile, problemfile, self.parse_plan(planfile))\n",
    "\n",
    "    def validate_plan(self, domainfile, problemfile, plan):\n",
    "        # Parser\n",
    "        parser = PDDL_Parser()\n",
    "        parser.parse_domain(domainfile)\n",
    "        parser.parse_problem(problemfile)\n",
    "        # Grounding process\n",
    "        ground_actions = []\n",
    "        for action in parser.actions:\n",
    "            for act in action.groundify(parser.objects):\n",
    "                ground_actions.append(act)\n",
    "        return self.validate(ground_actions, parser.state, parser.positive_goals, parser.negative_goals, plan)\n",
    "    \n",
    "    # =====================================\n",
    "    # Params:\n",
    "    # actions -> list of ground actions\n",
    "    # initial_state -> initial state of the problem file\n",
    "    # positive_goals -> positive predicates of the goal\n",
    "    # negative_goals -> negative predicates of the goal\n",
    "    # plan -> plan parsed from a plan trace\n",
    "    # =====================================\n",
    "    def validate(self, actions, initial_state, positive_goals, negative_goals, plan):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "57b0f4b1a8b05a4c5a0d68e8adb99df0",
     "grade": false,
     "grade_id": "cell-55fe55549d93781e",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Test the validate function\n",
    "In this test, we verify the correctness of the implemented validator using the **[dwr](examples/dwr)** domain. Consider running more tests to ensure the correctness of the implemented function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c82e1c97fbe2ccfe7c51d3325952c767",
     "grade": true,
     "grade_id": "validator-tests",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "dwr = \"examples/dwr/dwr.pddl\"\n",
    "pb1 = \"examples/dwr/pb1.pddl\"\n",
    "plan1 = \"examples/dwr/dwr_pb1_bfs.plan\"\n",
    "plan2 = \"examples/dwr/dwr_pb1_heuristic.plan\"\n",
    "plan_empty = \"examples/dwr/empty.plan\"\n",
    "val = Validator()\n",
    "print(\"Expected True, got:\", str(val.validate_file(dwr, pb1, plan1)))\n",
    "print(\"Expected True, got:\", str(val.validate_file(dwr, pb1, plan2)))\n",
    "print(\"Expected False, got:\", str(val.validate_file(dwr, pb1, plan_empty)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1b9b8570d1657571552de1f74bff6854",
     "grade": true,
     "grade_id": "cell-60fef55dca061cc3",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4e5e0cfa9c914d9907985c46310f1e65",
     "grade": false,
     "grade_id": "cell-39eca486536e5e39",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Planner\n",
    "\n",
    "## Implement the planner ```solve``` function\n",
    "You will implement the **A\\*** search. This search must use the implemented **Max-cost** heuristic. The search receives a **domain** pddl file and a **problem** pddl file (both are already parsed for you). The search must always return an optimal plan, given that there is a solution for the given problem in the specified domain. Your code must be contained in the ``solve(self, actions, initial_state, positive_goals, negative_goals)`` function (in the following cell). Solve takes the following inputs:\n",
    "- ``actions``: list of grounded actions\n",
    "- ``initial_state``: initial state of the problem file\n",
    "- ``positive_goals``: positive predicates of the goal\n",
    "- ``negative_goals``: negative predicates of the goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "0a610593228f933e9bf99aaa5fb4df07",
     "grade": false,
     "grade_id": "cell-b56ecf8f0cfc8d58",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from pddl.pddl_planner import PDDL_Planner\n",
    "from pddl.state import applicable, apply\n",
    "import sys\n",
    "import queue as queue\n",
    "\n",
    "class Heuristic_Planner(PDDL_Planner):\n",
    "\n",
    "    def __init__(self, heuristic=MaxHeuristic()):\n",
    "        self.h = heuristic\n",
    "\n",
    "    # -----------------------------------------------\n",
    "    # Solve\n",
    "    # -----------------------------------------------\n",
    "    \n",
    "    # =====================================\n",
    "    # Params:\n",
    "    # actions -> list of grounded actions\n",
    "    # initial_state -> initial state of the problem file\n",
    "    # positive_goals -> positive predicates of the goal\n",
    "    # negative_goals -> negative predicates of the goal\n",
    "    # =====================================\n",
    "    \n",
    "    def solve(self, actions, initial_state, positive_goals, negative_goals):\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return None # No plan was found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0785b88a9f787b68a5722b1b16edf7c2",
     "grade": false,
     "grade_id": "cell-82264e9b565f91ab",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Test planner completeness and optimality\n",
    "Here we perform a simple test to verify if the lenght of the plan found by your implementation is step optimal. Please note, that this test does not verify if the plan is valid (but we are going to test this). You can use your own implementation of the validator to verify this (highly recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3616f4c6d785dcfb36adf40431e59499",
     "grade": true,
     "grade_id": "cell-ba715b0523a236d4",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "#Student_tests\n",
    "dwr = \"examples/dwr/dwr.pddl\"\n",
    "pb1 = \"examples/dwr/pb1.pddl\"\n",
    "pb2 = \"examples/dwr/pb2.pddl\"\n",
    "planner = Heuristic_Planner()\n",
    "\n",
    "plan, time = planner.solve_file(dwr, pb1, False)\n",
    "print(\"Expected 17, got:\", str(len(plan)) + ('. Correct!' if len(plan) == 17 else '. False!'))\n",
    "plan, time = planner.solve_file(dwr, pb2, False)\n",
    "print(\"Expected 0, got:\", str(len(plan)) + ('. Correct!' if len(plan) == 0 else '. False!'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4ad7cf46b6ce78423b324fc9cd6f64b5",
     "grade": true,
     "grade_id": "cell-49e25fc2323b7f89",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "055b0d7508398801181013533f7735b3",
     "grade": false,
     "grade_id": "cell-3178ca0ccf8bd085",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Test planner output time\n",
    "\n",
    "Here we will test the output time of the implemented search function. The **maximum** acceptable output time is **60 seconds** for the given domains. Please consider that a good implementation should take less than 20 seconds (depending on the machine) for any of the given problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5b9bc0fd5b60150799ed3e412bf38517",
     "grade": true,
     "grade_id": "cell-1f9af625ea2fc997",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Student_tests\n",
    "dwr = \"examples/dwr/dwr.pddl\"\n",
    "pb1 = \"examples/dwr/pb1.pddl\"\n",
    "pb2 = \"examples/dwr/pb2.pddl\"\n",
    "planner = Heuristic_Planner()\n",
    "\n",
    "plan, time = planner.solve_file(dwr, pb1, False)\n",
    "print(\"Elapsed time:\", str(time) + (' Passed!' if time <= 60.0 else ' Timeout!'))\n",
    "\n",
    "plan, time = planner.solve_file(dwr, pb2, False)\n",
    "print(\"Elapsed time:\", str(time) + (' Passed!' if time <= 60.0 else ' Timeout!'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
